{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8-final"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "classificadores.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ln27DsPGtF6g"
      },
      "source": [
        "# Projeto #2 - Classificador supervisionado\n",
        "\n",
        "Antes de começar, leia as [Instruções](https://github.com/thvmm/pos-ds-ia/tree/master/projeto_2#instru%C3%A7%C3%B5es) e os [Critérios de Avaliação](https://github.com/thvmm/pos-ds-ia/tree/master/projeto_2#crit%C3%A9rios-de-avalia%C3%A7%C3%A3o)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5rvLywztF6j"
      },
      "source": [
        "### 1) Qual a base escolhida?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qTvRlRxttF6l"
      },
      "source": [
        "O dataset consiste em 20 grupos de notícias, que compreende cerca de 18.000 postagens de notícias, sobre 20 tópicos divididos em dois subconjuntos: um para treinamento e outro para teste. A divisão entre o treino e o conjunto de teste é baseada em mensagens postadas antes e depois de uma data específica.\n",
        "\n",
        "Características do dataset:\n",
        "\n",
        "Features   | Valor\n",
        "--------- | ------\n",
        "Classes | 20\n",
        "Amostras | 18846\n",
        "Dimensionalidade | 1\n",
        "Recursos | texto\n",
        "\n",
        "Link da base: https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YYZ6FDzftF6m"
      },
      "source": [
        "### 2) **(10%)** Pré-processamento: entendimento do conjunto de dados\n",
        "- Quais são minhas features?\n",
        "- Quais são minhas classes?\n",
        "- Como estão distribuidas minhas classes?\n",
        "- Checagem se os valores estão dentro de um limite permitido ou razoável.\n",
        "- Tratamento de valores ausentes por eliminação ou substituição.\n",
        "- Conversão do tipo de dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "colab_type": "code",
        "id": "VyTMRCWJ2bYg",
        "outputId": "55badeb5-8e4f-4662-dbbb-294cbe5d3cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['alt.atheism',\n",
            " 'comp.graphics',\n",
            " 'comp.os.ms-windows.misc',\n",
            " 'comp.sys.ibm.pc.hardware',\n",
            " 'comp.sys.mac.hardware',\n",
            " 'comp.windows.x',\n",
            " 'misc.forsale',\n",
            " 'rec.autos',\n",
            " 'rec.motorcycles',\n",
            " 'rec.sport.baseball',\n",
            " 'rec.sport.hockey',\n",
            " 'sci.crypt',\n",
            " 'sci.electronics',\n",
            " 'sci.med',\n",
            " 'sci.space',\n",
            " 'soc.religion.christian',\n",
            " 'talk.politics.guns',\n",
            " 'talk.politics.mideast',\n",
            " 'talk.politics.misc',\n",
            " 'talk.religion.misc']\n"
          ]
        }
      ],
      "source": [
        "# Implemente sua análise aqui. Use mais blocos se achar que ficará mais organizado.\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(list(newsgroups_train.target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "yr4N_CjJ24Ki",
        "outputId": "381ed294-0bf4-45bc-8acb-9fad31b6462e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2034,)\n",
            "(2034,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(newsgroups_train.filenames.shape)\n",
        "print(newsgroups_train.target.shape)\n",
        "newsgroups_train.target[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "colab_type": "code",
        "id": "DN6itUZ33SHn",
        "outputId": "43b203fc-7e3d-44f6-9cb1-29997a801ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'sci.space']\n",
            "(1073,)\n",
            "(1073,)\n",
            "[0 1 1 1 0 1 1 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "cats = ['alt.atheism', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
        "\n",
        "print(list(newsgroups_train.target_names))\n",
        "print(newsgroups_train.filenames.shape)\n",
        "print(newsgroups_train.target.shape)\n",
        "print(newsgroups_train.target[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "ifhG8Nud3ZHm",
        "outputId": "7accf0cb-0afd-45de-a223-fd634507b14a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2034, 34118)"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "categories = ['alt.atheism', 'talk.religion.misc','comp.graphics', 'sci.space']\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "W8NHofyx3jcx",
        "outputId": "e10f7bb7-7fdc-4ccc-d640-2588c47dcd9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "159.0132743362832"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectors.nnz / float(vectors.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xwj11_GTtF7E"
      },
      "source": [
        "### 3) **(80%)** Nos blocos seguintes implemente seus classificadores (serão implementados 2 métodos diferentes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b7H4RId2tF7F"
      },
      "source": [
        "#### 3.1) Qual método escolhido?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A6EHGaxhtF7H"
      },
      "source": [
        "**Indique o método escolhido**\n",
        "\n",
        "Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nUG1VmFrtF7I"
      },
      "source": [
        "#### 3.2) **(10%)** Baseline - Implemente seu classificador da forma mais simples possível para esse ser seu baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "fMZkkcANtF7J",
        "outputId": "ab6ac1e8-16b8-45b1-b2ea-d83545b04582"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7731035068127478"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Implementação. Use mais blocos se achar que ficará mais organizado.\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',\n",
        "                                      remove=('headers', 'footers', 'quotes'),\n",
        "                                      categories=categories)\n",
        "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
        "pred = clf.predict(vectors_test)\n",
        "metrics.f1_score(pred, newsgroups_test.target, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CQyLXeWNtF7M"
      },
      "source": [
        "#### 3.3) **(20%)** Versão 1 - O que podemos fazer para melhorar nosso baseline? Aplique técnicas como redução de dimensionalidade, normalização ou outras. Compare os resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "4W45H0-gtF7O",
        "outputId": "19d39e44-8e3a-4e1a-d6f4-f228321d7f3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Implementação. Use mais blocos se achar que ficará mais organizado.\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "                                       remove=('headers', 'footers', 'quotes'),\n",
        "                                       categories=categories)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "clf = MultinomialNB(alpha=.01)\n",
        "clf.fit(vectors, newsgroups_train.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "AaRt3x-j_Z7w",
        "outputId": "b92137d6-57f4-4c9c-e811-5861b6371a02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7699517518452172"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
        "pred = clf.predict(vectors_test)\n",
        "metrics.f1_score(newsgroups_test.target, pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qa5yVE9gtF7X"
      },
      "source": [
        "#### 3.4) **(10%)** Tunning - Agora que temos um resultado promissor, vamos tentar melhorar o resultado alterando um ou mais hiper-parametro. Compare os resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "KtM5otYGtF7Y",
        "outputId": "550a25fa-4f8d-4341-a63f-57db85e5e1e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Implementação. Use mais blocos se achar que ficará mais organizado.\n",
        "\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
        "\n",
        "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
        "clf = MultinomialNB(alpha=.01)\n",
        "clf.fit(vectors, newsgroups_train.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "PywWiRAl7svR",
        "outputId": "6babbfb4-f8bb-4a5b-a92b-50ba37e4aef9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8821359240272957"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = clf.predict(vectors_test)\n",
        "metrics.f1_score(newsgroups_test.target, pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oNBUThQCtF7c"
      },
      "source": [
        "#### 3.5) Qual método escolhido?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8n9bbXswtF7e"
      },
      "source": [
        "**Indique o método escolhido**\n",
        "\n",
        "Multiclass hinge loss with elastic net regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3z7y2O-HtF7f"
      },
      "source": [
        "#### 3.6) **(10%)** Baseline - Implemente seu classificador da forma mais simples possível para esse ser seu baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rvLn-EIDtF7g"
      },
      "outputs": [],
      "source": [
        "# Implementação. Use mais blocos se achar que ficará mais organizado.\n",
        "\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "import epopt as ep\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
        "newsgroups_test = fetch_20newsgroups(subset=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DqeAAF4jtF7k"
      },
      "source": [
        "#### 3.7) **(20%)** Versão 1 - O que podemos fazer para melhorar nosso baseline? Aplique técnicas como redução de dimensionalidade, normalização ou outras. Compare os resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zBtfc2bFtF7m"
      },
      "outputs": [],
      "source": [
        "# Implementação. Use mais blocos se achar que ficará mais organizado.\n",
        "\n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "vectorizer = text.TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(newsgroups_train.data)\n",
        "y = newsgroups_train.target\n",
        "Xtest = vectorizer.transform(newsgroups_test.data)\n",
        "ytest = newsgroups_test.target\n",
        "\n",
        "print (X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YKMyDvI4tF7q"
      },
      "source": [
        "#### 3.8) **(10%)** Tunning - Agora que temos um resultado promissor, vamos tentar melhorar o resultado alterando um ou mais hiper-parametro. Compare os resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tw8673svtF7r"
      },
      "outputs": [],
      "source": [
        "# Implementação. Use mais blocos se achar que ficará mais organizado.\n",
        "\n",
        "def multiclass_hinge_loss(Theta, X, y):\n",
        "    k = Theta.size[1]\n",
        "    Y = one_hot(y, k)\n",
        "    return (cp.sum_entries(cp.max_entries(X*Theta + 1 - Y, axis=1)) -\n",
        "            cp.sum_entries(cp.mul_elemwise(X.T.dot(Y), Theta)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FIix4tsHBXB5"
      },
      "outputs": [],
      "source": [
        "m, n = X.shape\n",
        "k = '20'\n",
        "Theta = cp.Variable(n, k)\n",
        "lam1 = 0.1\n",
        "lam2 = 1\n",
        "\n",
        "f = ep.multiclass_hinge_loss(Theta, X, y) + lam1*cp.norm1(Theta) + lam2*cp.sum_squares(Theta)\n",
        "prob = cp.Problem(cp.Minimize(f))\n",
        "ep.solve(prob, verbose=True)\n",
        "\n",
        "Theta0 = np.array(Theta.value)\n",
        "print (\"Train accuracy:\", accuracy(np.argmax(X.dot(Theta0), axis=1), y))\n",
        "print (\"Test accuracy:\", accuracy(np.argmax(Xtest.dot(Theta0), axis=1), ytest))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3o9PweG0tF7v"
      },
      "source": [
        "### 5) **(10%)** Conclusões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SC5-a5FztF7x"
      },
      "source": [
        "*Compare seus resultados. Imaginando que sua solução fosse para produção, qual deles você escolheria? Por que? Quais os riscos você enxerga? O que recomendaria de próximos passos para melhorar os resultados?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F5CJMY3FtF7y"
      },
      "source": [
        "No primeiro classificador ele se adequou de forma facil a coisas específicas que aparecem no dataset, como os cabeçalhos. Este classificador alcança uma acuracia muito alta, no entanto seus resultados não se generalizam para outros documentos que não estejam no mesmo espaco de tempo.\n",
        "\n",
        "Ja no segundo classificador foi utilizado uma abordagem direta de geração de recursos e um modelo simples de palavras-chave, foi atingido mais ou menos 80% de precisão. \n",
        "\n",
        "Nota-se que para esse dataset, a divisão por data tende a resultar em um erro de generalização menor que o esperado, pois previsivelmente devido ao fato de que o conteúdo de um grupo de notícias específico é mudado ao longo do tempo.\n",
        "\n",
        "Por tanto, sem dúvida, podemos melhorar esse resultado incluindo, por exemplo, higher order n-grams, colocando recursos de PNL mais sofisticados e várias outras abordagens para a engenharia de fetuares.\n",
        "\n"
      ]
    }
  ]
}